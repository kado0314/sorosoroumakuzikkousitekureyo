// ======================================
// 1. éŸ³å£°èªè­˜ (Web Speech API)
// ======================================
const startStopVoiceBtn = document.getElementById('startStopVoiceBtn');
const outputVoice = document.getElementById('outputVoice');
const voiceStatus = document.getElementById('voiceStatus');
const copyBtn = document.getElementById('copyBtn');

const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
let isListening = false;
let recognition = null;

if (SpeechRecognition) {
    recognition = new SpeechRecognition();
    recognition.lang = 'ja-JP';
    recognition.interimResults = true;
    recognition.continuous = true;

    recognition.onstart = () => {
        isListening = true;
        startStopVoiceBtn.textContent = 'åœæ­¢';
        voiceStatus.textContent = 'ğŸŸ¢ ãƒã‚¤ã‚¯ãŒã‚ªãƒ³ã€‚è©±ã—ã¦ãã ã•ã„...';
    };

    recognition.onresult = (event) => {
        let finalTranscript = '';
        let interimTranscript = '';
        for (let i = event.resultIndex; i < event.results.length; i++) {
            const transcript = event.results[i][0].transcript;
            if (event.results[i].isFinal) {
                finalTranscript += transcript + 'ã€‚';
            } else {
                interimTranscript += transcript;
            }
        }
        outputVoice.value = finalTranscript + interimTranscript;
    };

    recognition.onend = () => {
        if (isListening) recognition.start();
        else voiceStatus.textContent = 'å¾…æ©Ÿä¸­...';
    };

    recognition.onerror = (event) => {
        console.error('èªè­˜ã‚¨ãƒ©ãƒ¼:', event.error);
        voiceStatus.textContent = `ğŸ”´ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: ${event.error}`;
        isListening = false;
        startStopVoiceBtn.textContent = 'ğŸ”´ éŸ³å£°èªè­˜ã‚’é–‹å§‹';
    };

    startStopVoiceBtn.addEventListener('click', () => {
        if (isListening) {
            isListening = false;
            recognition.stop();
        } else {
            outputVoice.value = '';
            recognition.start();
        }
    });
} else {
    voiceStatus.textContent = "ğŸš¨ ãƒ–ãƒ©ã‚¦ã‚¶ãŒéŸ³å£°èªè­˜APIã«å¯¾å¿œã—ã¦ã„ã¾ã›ã‚“ã€‚";
    startStopVoiceBtn.disabled = true;
}

copyBtn.addEventListener('click', () => {
    navigator.clipboard.writeText(outputVoice.value);
    copyBtn.textContent = 'âœ… ã‚³ãƒ”ãƒ¼å®Œäº†!';
    setTimeout(() => copyBtn.textContent = 'ğŸ“‹ ãƒ†ã‚­ã‚¹ãƒˆã‚’ã‚³ãƒ”ãƒ¼', 1500);
});


// ======================================
// 2. ã‚«ãƒ¡ãƒ©åˆ¶å¾¡ (MediaDevices API)
// ======================================
const toggleCameraBtn = document.getElementById('toggleCameraBtn');
const webcamVideo = document.getElementById('webcamVideo');
const overlayCanvas = document.getElementById('overlayCanvas');
const cameraStatus = document.getElementById('cameraStatus');

let cameraStream = null;
let isCameraOn = false;
let detectionInterval = null;

// ã‚«ãƒ¡ãƒ©èµ·å‹•/åœæ­¢ã‚’åˆ¶å¾¡ã™ã‚‹é–¢æ•°
const toggleCamera = async () => {
    if (isCameraOn) {
        // ã‚«ãƒ¡ãƒ©åœæ­¢
        if (cameraStream) {
            cameraStream.getTracks().forEach(track => track.stop());
        }
        webcamVideo.style.display = 'none';
        overlayCanvas.style.display = 'none';
        cameraStatus.textContent = 'ã‚«ãƒ¡ãƒ©ã¯ã‚ªãƒ•ã§ã™';
        toggleCameraBtn.textContent = 'é€šçŸ¥ãƒœã‚¿ãƒ³ (ã‚«ãƒ¡ãƒ©èµ·å‹•)';
        clearInterval(detectionInterval); // èªè­˜å‡¦ç†ã®åœæ­¢
        isCameraOn = false;
    } else {
        // ã‚«ãƒ¡ãƒ©èµ·å‹•
        try {
            cameraStream = await navigator.mediaDevices.getUserMedia({ video: true, audio: false });
            webcamVideo.srcObject = cameraStream;
            webcamVideo.style.display = 'block';
            overlayCanvas.style.display = 'block';
            cameraStatus.textContent = 'ğŸŸ¢ ã‚«ãƒ¡ãƒ©ã‚ªãƒ³ã€‚ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰ä¸­...';
            toggleCameraBtn.textContent = 'åœæ­¢';
            isCameraOn = true;
            
            webcamVideo.onloadedmetadata = () => {
                // face-logic.jsã§å®šç¾©ã•ã‚ŒãŸé–¢æ•°ã‚’å‘¼ã³å‡ºã—ã€é¡”èªè­˜ãƒ«ãƒ¼ãƒ—ã‚’é–‹å§‹
                detectionInterval = startFaceDetection(webcamVideo, overlayCanvas, cameraStatus); 
            };
        } catch (err) {
            console.error('ã‚«ãƒ¡ãƒ©ã‚¢ã‚¯ã‚»ã‚¹ã‚¨ãƒ©ãƒ¼:', err);
            cameraStatus.textContent = 'ğŸš¨ ã‚«ãƒ¡ãƒ©ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ãŒæ‹’å¦ã•ã‚Œã¾ã—ãŸã€‚';
            toggleCameraBtn.textContent = 'é€šçŸ¥ãƒœã‚¿ãƒ³ (ã‚«ãƒ¡ãƒ©èµ·å‹•)';
        }
    }
};

// -------------------------------------
// 3. åˆæœŸåŒ–å‡¦ç†ã®é›†ç´„
// -------------------------------------
document.addEventListener('DOMContentLoaded', () => {
    // 1. ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰ã®é–‹å§‹ (face-logic.jsã‹ã‚‰å‘¼ã³å‡ºã—)
    // âš ï¸ ã“ã‚ŒãŒæˆåŠŸã—ãªã„ã¨ã€é¡”èªè­˜æ©Ÿèƒ½ã¯å‹•ãã¾ã›ã‚“ã€‚
    loadModels(); 

    // 2. ã‚«ãƒ¡ãƒ©èµ·å‹•/åœæ­¢ãƒœã‚¿ãƒ³ã®ã‚¤ãƒ™ãƒ³ãƒˆè¨­å®š
    toggleCameraBtn.addEventListener('click', toggleCamera);
    
    // 3. é¡”ç™»éŒ²ãƒœã‚¿ãƒ³ã®ã‚¤ãƒ™ãƒ³ãƒˆè¨­å®š (face-logic.jsã‹ã‚‰ç§»å‹•)
    document.getElementById('registerFaceBtn').addEventListener('click', () => {
        const name = document.getElementById('personName').value.trim();
        const files = document.getElementById('imageUpload').files;
        // face-logic.jsã®registerFaceé–¢æ•°ã‚’å‘¼ã³å‡ºã™
        registerFace(name, files);
    });
    
    // 4. ç™»éŒ²ãƒªã‚¹ãƒˆã®åˆæœŸæç”» (face-logic.jsã‹ã‚‰ç§»å‹•)
    updateRegisteredList();
});
